{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "header"
   },
   "source": [
    "# üöÄ Advanced Semantic Scoring - State-of-the-Art Models\n",
    "\n",
    "## Upgraded with Best Multilingual Models\n",
    "\n",
    "This notebook uses **cutting-edge models** for maximum accuracy:\n",
    "\n",
    "### üéØ Model Options:\n",
    "1. **BGE-M3** - State-of-the-art (BEST quality)\n",
    "2. **E5-Large** - Excellent multilingual embeddings\n",
    "3. **MPNet-Base** - High quality, fast\n",
    "4. **Ensemble** - Combine multiple models for maximum accuracy\n",
    "\n",
    "### üìä Scores:\n",
    "- **Innovation Score**: How innovative/cutting-edge\n",
    "- **Confidence Score**: How confident/established\n",
    "- **Market Clarity Score**: How clearly defined\n",
    "- **Overall Quality Score**: Combined metric\n",
    "\n",
    "**Optimized for 100+ GB RAM Colab**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup"
   },
   "source": [
    "## üì¶ Step 1: Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Install packages\n",
    "!pip install -q sentence-transformers pandas numpy torch tqdm matplotlib\n",
    "\n",
    "print(\"‚úÖ Installation complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "check-gpu"
   },
   "outputs": [],
   "source": [
    "# Check GPU\n",
    "import torch\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"GPU STATUS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"GPU Available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU Name: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "    print(\"‚úÖ Ready for high-speed processing!\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No GPU detected - will use CPU (slower)\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "upload"
   },
   "source": [
    "## üìÅ Step 2: Upload Your Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "upload-file"
   },
   "outputs": [],
   "source": [
    "# Option A: Upload file\n",
    "from google.colab import files\n",
    "\n",
    "print(\"üì§ Upload your CSV file...\")\n",
    "uploaded = files.upload()\n",
    "\n",
    "input_file = list(uploaded.keys())[0]\n",
    "print(f\"\\n‚úÖ Uploaded: {input_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mount-drive"
   },
   "outputs": [],
   "source": [
    "# Option B: Mount Google Drive (uncomment to use)\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# input_file = '/content/drive/MyDrive/your_file.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "config"
   },
   "source": [
    "## ‚öôÔ∏è Step 3: Configuration\n",
    "\n",
    "### Choose Your Model:\n",
    "\n",
    "| Model | Quality | Speed | Best For |\n",
    "|-------|---------|-------|----------|\n",
    "| `bge-m3` | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | Medium | **Maximum accuracy** |\n",
    "| `e5-large` | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | Medium | **High quality multilingual** |\n",
    "| `mpnet-base` | ‚≠ê‚≠ê‚≠ê‚≠ê | Fast | **Balanced** |\n",
    "| `minilm` | ‚≠ê‚≠ê‚≠ê | Very Fast | **Large datasets** |\n",
    "| `ensemble` | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | Slow | **Best possible accuracy** |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "config-cell"
   },
   "outputs": [],
   "source": [
    "# ========== CONFIGURATION ==========\n",
    "\n",
    "# MODEL SELECTION (choose one)\n",
    "MODEL = 'bge-m3'  # Options: 'bge-m3', 'e5-large', 'mpnet-base', 'minilm', 'ensemble'\n",
    "\n",
    "# DATASET SETTINGS\n",
    "DESCRIPTION_COLUMN = 'company_description'  # Name of your description column\n",
    "\n",
    "# PERFORMANCE SETTINGS\n",
    "BATCH_SIZE = 512  # 512-1024 for 100GB GPU, 256 for smaller GPUs\n",
    "\n",
    "# OUTPUT\n",
    "OUTPUT_FILE = 'scored_startups_advanced.csv'\n",
    "\n",
    "print(\"‚öôÔ∏è Configuration:\")\n",
    "print(f\"   Model: {MODEL}\")\n",
    "print(f\"   Batch size: {BATCH_SIZE}\")\n",
    "print(f\"   Output: {OUTPUT_FILE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "model-info"
   },
   "source": [
    "## üîß Step 4: Load Advanced Scoring Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "model-defs"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from typing import List, Dict, Optional\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Model configurations\n",
    "MODELS = {\n",
    "    'bge-m3': {\n",
    "        'name': 'BAAI/bge-m3',\n",
    "        'quality': '‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê BEST',\n",
    "        'description': 'State-of-the-art multilingual (100+ languages)'\n",
    "    },\n",
    "    'e5-large': {\n",
    "        'name': 'intfloat/multilingual-e5-large',\n",
    "        'quality': '‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê EXCELLENT',\n",
    "        'description': 'E5 embeddings - very high quality'\n",
    "    },\n",
    "    'mpnet-base': {\n",
    "        'name': 'sentence-transformers/paraphrase-multilingual-mpnet-base-v2',\n",
    "        'quality': '‚≠ê‚≠ê‚≠ê‚≠ê HIGH',\n",
    "        'description': 'MPNet-based, fast and accurate'\n",
    "    },\n",
    "    'minilm': {\n",
    "        'name': 'paraphrase-multilingual-MiniLM-L12-v2',\n",
    "        'quality': '‚≠ê‚≠ê‚≠ê GOOD',\n",
    "        'description': 'Very fast, good for large datasets'\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"‚úÖ Model configurations loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "scorer-class"
   },
   "outputs": [],
   "source": [
    "class AdvancedSemanticScorer:\n",
    "    \"\"\"Advanced semantic scorer with state-of-the-art models.\"\"\"\n",
    "\n",
    "    def __init__(self, model_key='bge-m3', batch_size=512):\n",
    "        if model_key not in MODELS:\n",
    "            raise ValueError(f\"Unknown model: {model_key}\")\n",
    "\n",
    "        model_config = MODELS[model_key]\n",
    "        model_name = model_config['name']\n",
    "\n",
    "        print(\"=\"*70)\n",
    "        print(\"üöÄ ADVANCED SEMANTIC SCORER\")\n",
    "        print(\"=\"*70)\n",
    "        print(f\"Model: {model_name}\")\n",
    "        print(f\"Quality: {model_config['quality']}\")\n",
    "        print(f\"Description: {model_config['description']}\")\n",
    "        print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        print(f\"Loading model on {self.device}...\")\n",
    "        self.model = SentenceTransformer(model_name, device=self.device)\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        # Enhanced reference texts for better accuracy\n",
    "        self.reference_texts = {\n",
    "            'innovation': [\n",
    "                \"Revolutionary breakthrough technology disrupting traditional industries with unprecedented innovation\",\n",
    "                \"Cutting-edge artificial intelligence and machine learning achieving state-of-the-art results\",\n",
    "                \"Novel solution using advanced patented technology never seen before in the market\",\n",
    "                \"Pioneering new approach with proprietary technology and unique methodology\",\n",
    "                \"Next-generation platform leveraging emerging technologies like quantum computing\",\n",
    "                \"Groundbreaking research-based innovation transforming the industry fundamentally\",\n",
    "                \"First-of-its-kind solution introducing completely new paradigm\",\n",
    "                \"Disruptive technology challenging established market leaders\",\n",
    "                \"Advanced R&D resulting in breakthrough capabilities\",\n",
    "                \"Revolutionary approach reimagining traditional processes\"\n",
    "            ],\n",
    "            'confidence': [\n",
    "                \"Proven track record with established customer base generating consistent revenue\",\n",
    "                \"Successfully deployed solution serving thousands of paying customers globally\",\n",
    "                \"Market leader with strong partnerships and extensively validated product\",\n",
    "                \"Demonstrated traction with measurable growth and strong profitability\",\n",
    "                \"Established company with successful case studies and testimonials\",\n",
    "                \"Operating at scale with proven repeatable business model\",\n",
    "                \"Trusted by Fortune 500 companies and industry leaders\",\n",
    "                \"99.9% uptime with enterprise-grade reliability\",\n",
    "                \"Growing customer base with high retention rates\",\n",
    "                \"Award-winning solution recognized by industry authorities\"\n",
    "            ],\n",
    "            'market_clarity': [\n",
    "                \"Clear value proposition solving specific problem for well-defined target market\",\n",
    "                \"Precisely addressing enterprise healthcare compliance with quantifiable ROI\",\n",
    "                \"Serving small retail businesses with streamlined inventory management\",\n",
    "                \"Focused solution for financial services regulatory compliance\",\n",
    "                \"Targeted platform connecting buyers and sellers in construction industry\",\n",
    "                \"Well-defined offering for specific customer segment with measurable benefits\",\n",
    "                \"Solving specific problem for specific market with specific solution\",\n",
    "                \"Reducing costs by X percent for Y industry through Z approach\",\n",
    "                \"Helping target customers achieve specific outcomes in measurable timeframe\",\n",
    "                \"Clear go-to-market strategy targeting specific segment\"\n",
    "            ]\n",
    "        }\n",
    "\n",
    "        print(\"Computing reference embeddings...\")\n",
    "        self.reference_embeddings = {}\n",
    "        for score_type, texts in self.reference_texts.items():\n",
    "            emb = self.model.encode(\n",
    "                texts,\n",
    "                convert_to_tensor=True,\n",
    "                show_progress_bar=False,\n",
    "                device=self.device,\n",
    "                normalize_embeddings=True\n",
    "            )\n",
    "            self.reference_embeddings[score_type] = emb\n",
    "\n",
    "        print(\"‚úÖ Ready!\\n\")\n",
    "\n",
    "    def score_descriptions(self, descriptions: List[str]) -> pd.DataFrame:\n",
    "        \"\"\"Score descriptions with advanced model.\"\"\"\n",
    "        descriptions = [str(d) if pd.notna(d) and str(d).strip()\n",
    "                       else \"No description\" for d in descriptions]\n",
    "\n",
    "        n = len(descriptions)\n",
    "        print(f\"Scoring {n:,} descriptions with batch size {self.batch_size}\\n\")\n",
    "\n",
    "        # Encode all descriptions\n",
    "        print(\"Encoding descriptions...\")\n",
    "        all_embeddings = self.model.encode(\n",
    "            descriptions,\n",
    "            batch_size=self.batch_size,\n",
    "            convert_to_tensor=True,\n",
    "            show_progress_bar=True,\n",
    "            device=self.device,\n",
    "            normalize_embeddings=True\n",
    "        )\n",
    "\n",
    "        # Compute scores\n",
    "        scores = {}\n",
    "        print(\"\\nComputing semantic scores...\")\n",
    "\n",
    "        for score_type in ['innovation', 'confidence', 'market_clarity']:\n",
    "            # Compute similarities\n",
    "            similarity = torch.mm(all_embeddings, self.reference_embeddings[score_type].T)\n",
    "            max_similarity = torch.max(similarity, dim=1)[0]\n",
    "            scores[score_type] = max_similarity.cpu().numpy()\n",
    "            print(f\"  ‚úì {score_type}\")\n",
    "\n",
    "        # Create DataFrame\n",
    "        results_df = pd.DataFrame({\n",
    "            'innovation_score': scores['innovation'],\n",
    "            'confidence_score': scores['confidence'],\n",
    "            'market_clarity_score': scores['market_clarity']\n",
    "        })\n",
    "\n",
    "        # Scale to 0-100\n",
    "        for col in results_df.columns:\n",
    "            raw = results_df[col]\n",
    "            results_df[col] = ((raw - raw.min()) / (raw.max() - raw.min()) * 100).clip(0, 100)\n",
    "\n",
    "        # Add overall quality score\n",
    "        results_df['overall_quality_score'] = (\n",
    "            results_df['innovation_score'] * 0.35 +\n",
    "            results_df['confidence_score'] * 0.35 +\n",
    "            results_df['market_clarity_score'] * 0.30\n",
    "        )\n",
    "\n",
    "        print(\"\\n‚úÖ Scoring complete!\")\n",
    "        return results_df\n",
    "\n",
    "    def score_dataframe(self, df, description_column, output_path=None):\n",
    "        \"\"\"Score DataFrame.\"\"\"\n",
    "        if description_column not in df.columns:\n",
    "            raise ValueError(f\"Column '{description_column}' not found!\")\n",
    "\n",
    "        scores_df = self.score_descriptions(df[description_column].tolist())\n",
    "        result_df = pd.concat([df.reset_index(drop=True), scores_df], axis=1)\n",
    "\n",
    "        if output_path:\n",
    "            print(f\"\\nüíæ Saving to {output_path}...\")\n",
    "            result_df.to_csv(output_path, index=False)\n",
    "            print(\"‚úÖ Saved!\")\n",
    "\n",
    "        return result_df\n",
    "\n",
    "print(\"‚úÖ AdvancedSemanticScorer loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ensemble-class"
   },
   "outputs": [],
   "source": [
    "class EnsembleScorer:\n",
    "    \"\"\"Ensemble scorer combining multiple models for maximum accuracy.\"\"\"\n",
    "\n",
    "    def __init__(self, models=['bge-m3', 'e5-large'], batch_size=512):\n",
    "        print(\"=\"*70)\n",
    "        print(\"üéØ ENSEMBLE SCORER (Maximum Accuracy)\")\n",
    "        print(\"=\"*70)\n",
    "        print(f\"Combining {len(models)} models:\\n\")\n",
    "\n",
    "        for model in models:\n",
    "            print(f\"  ‚Ä¢ {model}: {MODELS[model]['description']}\")\n",
    "\n",
    "        print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "        self.scorers = []\n",
    "        for model in models:\n",
    "            print(f\"Loading {model}...\\n\")\n",
    "            scorer = AdvancedSemanticScorer(model, batch_size)\n",
    "            self.scorers.append(scorer)\n",
    "\n",
    "        print(\"\\n‚úÖ Ensemble ready!\\n\")\n",
    "\n",
    "    def score_descriptions(self, descriptions: List[str]) -> pd.DataFrame:\n",
    "        \"\"\"Score using ensemble.\"\"\"\n",
    "        all_scores = []\n",
    "\n",
    "        for i, scorer in enumerate(self.scorers):\n",
    "            print(f\"\\n{'='*70}\")\n",
    "            print(f\"Model {i+1}/{len(self.scorers)}\")\n",
    "            print('='*70)\n",
    "            scores = scorer.score_descriptions(descriptions)\n",
    "            all_scores.append(scores)\n",
    "\n",
    "        print(\"\\nüîÑ Combining scores...\")\n",
    "        ensemble_scores = sum(all_scores) / len(all_scores)\n",
    "\n",
    "        print(\"‚úÖ Ensemble complete!\")\n",
    "        return ensemble_scores\n",
    "\n",
    "    def score_dataframe(self, df, description_column, output_path=None):\n",
    "        \"\"\"Score DataFrame with ensemble.\"\"\"\n",
    "        if description_column not in df.columns:\n",
    "            raise ValueError(f\"Column '{description_column}' not found!\")\n",
    "\n",
    "        scores_df = self.score_descriptions(df[description_column].tolist())\n",
    "        result_df = pd.concat([df.reset_index(drop=True), scores_df], axis=1)\n",
    "\n",
    "        if output_path:\n",
    "            print(f\"\\nüíæ Saving to {output_path}...\")\n",
    "            result_df.to_csv(output_path, index=False)\n",
    "            print(\"‚úÖ Saved!\")\n",
    "\n",
    "        return result_df\n",
    "\n",
    "print(\"‚úÖ EnsembleScorer loaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "quick-test"
   },
   "source": [
    "## üß™ Step 5: Quick Test (Optional)\n",
    "\n",
    "Test the model on sample descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "test-cell"
   },
   "outputs": [],
   "source": [
    "# Quick test\n",
    "test_descriptions = [\n",
    "    \"Revolutionary AI-powered healthcare diagnostics with proven clinical results and FDA approval\",\n",
    "    \"Our platform serves 50,000+ enterprise customers with 99.99% uptime and strong revenue\",\n",
    "    \"Helping small retailers reduce inventory costs by 40% with clear ROI in 6 months\",\n",
    "    \"Startup exploring opportunities in tech\",\n",
    "    \"Quantum computing breakthrough with proprietary algorithms transforming drug discovery\"\n",
    "]\n",
    "\n",
    "print(\"üß™ Testing with sample descriptions...\\n\")\n",
    "\n",
    "test_scorer = AdvancedSemanticScorer(model_key=MODEL, batch_size=32)\n",
    "test_scores = test_scorer.score_descriptions(test_descriptions)\n",
    "\n",
    "test_results = pd.DataFrame({\n",
    "    'Description': [d[:50] + '...' for d in test_descriptions],\n",
    "    'Innovation': test_scores['innovation_score'].round(1),\n",
    "    'Confidence': test_scores['confidence_score'].round(1),\n",
    "    'Clarity': test_scores['market_clarity_score'].round(1),\n",
    "    'Overall': test_scores['overall_quality_score'].round(1)\n",
    "})\n",
    "\n",
    "print(\"\\nüìä Test Results:\")\n",
    "print(\"=\"*100)\n",
    "print(test_results.to_string(index=False))\n",
    "print(\"=\"*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "process"
   },
   "source": [
    "## üöÄ Step 6: Process Your Full Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "load-data"
   },
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "print(f\"Loading data from: {input_file}\\n\")\n",
    "df = pd.read_csv(input_file)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"DATASET INFO\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Rows: {len(df):,}\")\n",
    "print(f\"Columns: {len(df.columns)}\")\n",
    "print(f\"\\nAvailable columns:\")\n",
    "for col in df.columns:\n",
    "    print(f\"  ‚Ä¢ {col}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Check description column\n",
    "if DESCRIPTION_COLUMN not in df.columns:\n",
    "    print(f\"\\n‚ö†Ô∏è Column '{DESCRIPTION_COLUMN}' not found!\")\n",
    "    print(\"Please update DESCRIPTION_COLUMN in Step 3\")\n",
    "else:\n",
    "    print(f\"\\n‚úÖ Using column: '{DESCRIPTION_COLUMN}'\")\n",
    "    sample_desc = str(df[DESCRIPTION_COLUMN].iloc[0])[:150]\n",
    "    print(f\"Sample: {sample_desc}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "score-all"
   },
   "outputs": [],
   "source": [
    "# Initialize scorer based on MODEL setting\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STARTING SEMANTIC SCORING\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "if MODEL == 'ensemble':\n",
    "    # Use ensemble of best models\n",
    "    scorer = EnsembleScorer(models=['bge-m3', 'e5-large'], batch_size=BATCH_SIZE)\n",
    "else:\n",
    "    # Use single model\n",
    "    scorer = AdvancedSemanticScorer(model_key=MODEL, batch_size=BATCH_SIZE)\n",
    "\n",
    "# Process all descriptions\n",
    "result_df = scorer.score_dataframe(\n",
    "    df,\n",
    "    description_column=DESCRIPTION_COLUMN,\n",
    "    output_path=OUTPUT_FILE\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"‚úÖ SCORING COMPLETE!\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "analyze"
   },
   "source": [
    "## üìä Step 7: Analyze Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "stats"
   },
   "outputs": [],
   "source": [
    "# Statistics\n",
    "score_cols = ['innovation_score', 'confidence_score', 'market_clarity_score', 'overall_quality_score']\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"SCORE STATISTICS\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "print(result_df[score_cols].describe().round(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "top-scorers"
   },
   "outputs": [],
   "source": [
    "# Top scorers\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TOP 5 COMPANIES BY CATEGORY\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "print(\"üöÄ Most Innovative:\")\n",
    "print(result_df.nlargest(5, 'innovation_score')[['name', 'innovation_score', DESCRIPTION_COLUMN]].to_string(index=False))\n",
    "\n",
    "print(\"\\nüí™ Most Confident:\")\n",
    "print(result_df.nlargest(5, 'confidence_score')[['name', 'confidence_score', DESCRIPTION_COLUMN]].to_string(index=False))\n",
    "\n",
    "print(\"\\nüéØ Best Market Clarity:\")\n",
    "print(result_df.nlargest(5, 'market_clarity_score')[['name', 'market_clarity_score', DESCRIPTION_COLUMN]].to_string(index=False))\n",
    "\n",
    "print(\"\\n‚≠ê Highest Overall Quality:\")\n",
    "print(result_df.nlargest(5, 'overall_quality_score')[['name', 'overall_quality_score', DESCRIPTION_COLUMN]].to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "visualize"
   },
   "outputs": [],
   "source": [
    "# Visualizations\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "fig.suptitle('Semantic Score Distributions', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Innovation\n",
    "result_df['innovation_score'].hist(bins=50, ax=axes[0,0], color='#FF6B6B', alpha=0.7, edgecolor='black')\n",
    "axes[0,0].set_title('Innovation Score', fontsize=12, fontweight='bold')\n",
    "axes[0,0].set_xlabel('Score')\n",
    "axes[0,0].set_ylabel('Frequency')\n",
    "axes[0,0].axvline(result_df['innovation_score'].mean(), color='red', linestyle='--', label=f\"Mean: {result_df['innovation_score'].mean():.1f}\")\n",
    "axes[0,0].legend()\n",
    "\n",
    "# Confidence\n",
    "result_df['confidence_score'].hist(bins=50, ax=axes[0,1], color='#4ECDC4', alpha=0.7, edgecolor='black')\n",
    "axes[0,1].set_title('Confidence Score', fontsize=12, fontweight='bold')\n",
    "axes[0,1].set_xlabel('Score')\n",
    "axes[0,1].set_ylabel('Frequency')\n",
    "axes[0,1].axvline(result_df['confidence_score'].mean(), color='darkgreen', linestyle='--', label=f\"Mean: {result_df['confidence_score'].mean():.1f}\")\n",
    "axes[0,1].legend()\n",
    "\n",
    "# Market Clarity\n",
    "result_df['market_clarity_score'].hist(bins=50, ax=axes[1,0], color='#FFD93D', alpha=0.7, edgecolor='black')\n",
    "axes[1,0].set_title('Market Clarity Score', fontsize=12, fontweight='bold')\n",
    "axes[1,0].set_xlabel('Score')\n",
    "axes[1,0].set_ylabel('Frequency')\n",
    "axes[1,0].axvline(result_df['market_clarity_score'].mean(), color='orange', linestyle='--', label=f\"Mean: {result_df['market_clarity_score'].mean():.1f}\")\n",
    "axes[1,0].legend()\n",
    "\n",
    "# Overall Quality\n",
    "result_df['overall_quality_score'].hist(bins=50, ax=axes[1,1], color='#A8E6CF', alpha=0.7, edgecolor='black')\n",
    "axes[1,1].set_title('Overall Quality Score', fontsize=12, fontweight='bold')\n",
    "axes[1,1].set_xlabel('Score')\n",
    "axes[1,1].set_ylabel('Frequency')\n",
    "axes[1,1].axvline(result_df['overall_quality_score'].mean(), color='darkblue', linestyle='--', label=f\"Mean: {result_df['overall_quality_score'].mean():.1f}\")\n",
    "axes[1,1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"üìä Distributions plotted!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "correlation"
   },
   "outputs": [],
   "source": [
    "# Score correlations\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "correlation = result_df[score_cols].corr()\n",
    "sns.heatmap(correlation, annot=True, cmap='coolwarm', center=0, \n",
    "            square=True, linewidths=1, fmt='.2f')\n",
    "plt.title('Score Correlations', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"üîó Correlation matrix plotted!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "download"
   },
   "source": [
    "## üì• Step 8: Download Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "download-file"
   },
   "outputs": [],
   "source": [
    "# Download results\n",
    "from google.colab import files\n",
    "\n",
    "print(f\"üì• Downloading {OUTPUT_FILE}...\")\n",
    "files.download(OUTPUT_FILE)\n",
    "print(\"‚úÖ Download complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "notes"
   },
   "source": [
    "## üìù Model Performance Notes\n",
    "\n",
    "### Expected Processing Time (20k rows):\n",
    "\n",
    "**Single Model:**\n",
    "- **BGE-M3** (A100 100GB): ~2-3 minutes with batch_size=1024\n",
    "- **E5-Large** (A100 100GB): ~2-3 minutes with batch_size=1024  \n",
    "- **MPNet-Base** (V100 16GB): ~3-4 minutes with batch_size=512\n",
    "- **MiniLM** (T4 16GB): ~5-7 minutes with batch_size=512\n",
    "\n",
    "**Ensemble (BGE-M3 + E5-Large):**\n",
    "- A100 100GB: ~5-6 minutes (best accuracy)\n",
    "\n",
    "### Quality Comparison:\n",
    "\n",
    "| Model | Accuracy | Languages | Speed |\n",
    "|-------|----------|-----------|-------|\n",
    "| BGE-M3 | ‚òÖ‚òÖ‚òÖ‚òÖ‚òÖ | 100+ | Medium |\n",
    "| E5-Large | ‚òÖ‚òÖ‚òÖ‚òÖ‚òÖ | 100+ | Medium |\n",
    "| Ensemble | ‚òÖ‚òÖ‚òÖ‚òÖ‚òÖ+ | 100+ | Slow |\n",
    "| MPNet | ‚òÖ‚òÖ‚òÖ‚òÖ | 50+ | Fast |\n",
    "| MiniLM | ‚òÖ‚òÖ‚òÖ | 50+ | Very Fast |\n",
    "\n",
    "### Tips:\n",
    "- Use **BGE-M3** or **E5-Large** for best quality\n",
    "- Use **Ensemble** for maximum accuracy (research/critical applications)\n",
    "- Use **MPNet** for balanced quality/speed\n",
    "- Increase `batch_size` to 1024-2048 with 100GB GPU\n",
    "- All models handle multilingual descriptions automatically"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Advanced Semantic Scoring - State-of-the-Art Models",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
